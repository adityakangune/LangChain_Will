# LangChain_Will
A lightweight LLM-powered tool to extract and summarize key information from long PDF wills using open-source models, FAISS for vector search, and HuggingFace Transformers. Ideal for legal assistants and researchers.

# Will Summarizer using LLMs ğŸ§ ğŸ“œ

This project uses free, local large language models and vector databases to summarize lengthy legal documentsâ€”specifically wills (100+ pages)â€”by breaking them into chunks, indexing with FAISS, and querying relevant sections to generate concise summaries.

## ğŸ”§ Features
- âœ… PDF to text parsing with intelligent chunking
- âœ… FAISS vector store for semantic search
- âœ… HuggingFace models (e.g., Flan-T5) for generation
- âœ… Open-source and local (no OpenAI key needed)
- âœ… Custom queries for legal exploration

## ğŸ“ Steps
1. **Ingest PDF and split into semantic chunks**
2. **Embed with sentence transformers**
3. **Store/retrieve with FAISS**
4. **Generate summaries from relevant chunks**

## ğŸ“¦ Models
- Embedding: `all-MiniLM-L6-v2`
- Generation: `google/flan-t5-base` (fully free)

## ğŸ’¡ Example Usage
```bash
python step3_query_local.py
â“ Ask something about the will: Who gets the estate?
